{"nbformat":4,"nbformat_minor":0,"metadata":{"orig_nbformat":2,"kernelspec":{"name":"python_defaultSpec_1596674886897","display_name":"Python 3.6.10 64-bit ('igcmf': conda)"},"colab":{"name":"IGCMF.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"OoO4o8X9DhVs","colab_type":"code","colab":{}},"source":["import numpy as np\n","import torch\n","import pandas as pd\n","import numpy as np\n","#\n","import pickle as pkl\n","#\n","from sklearn import preprocessing\n","#\n","import matplotlib\n","matplotlib.use('agg')"],"execution_count":1,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"1.5.0\n10.1\n"}],"source":["print(torch.__version__) # v1.5.0\n","print(torch.version.cuda) # v10.2"]},{"cell_type":"code","metadata":{"id":"IPN32L8SESFZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":324},"executionInfo":{"status":"error","timestamp":1596604696557,"user_tz":-600,"elapsed":884,"user":{"displayName":"Riordan Alfredo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLt9xRjtNZnB33NvOyHKPHq5AVG7hsg4zHVdcDCg=s64","userId":"12730100241040769811"}},"outputId":"aec93b43-247f-4474-c42a-22bd0dc752dc"},"source":["from torch_geometric.nn import GCNConv, RGCNConv, global_sort_pool, global_add_pool\n","from torch_geometric.utils import dropout_adj"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zxoIiwpuZdpC"},"source":["# Overall Architecture\n","\n","0. Arrange multi-view matrices (prepare matrices)\n","1. Select closely related matrices (matrices that share common entity)\n","2. Generate subgraphs (multi-partite graphs) for all matrix groups\n","3. Node labeling \n","4. Transform a multi-partite graph to bipartite graphs as layers\n","5. Group up similar bipartite-graphs for training (inspired by IGMC)\n","6. Training with GNN using multiple layers (potentially using R-GCN) concurrently\n","\n","**Loss function**: Reduce MSE with random bias for each layers (need to revisit GC-MC and R-GCN)\n","\n","**Optimization**: Adam optimizer\n","\n","**Evaluation with other models**: RMSE and AUC\n"]},{"cell_type":"code","metadata":{"id":"fi5SHuWeESFd","colab_type":"code","colab":{}},"source":["# initialise all necesarry functions here. Maybe should be moved to another file and import later\n","def one_hot(idx, length):\n","    idx = np.array(idx)\n","    x = np.zeros([len(idx), length])\n","    x[np.arange(len(idx)), idx] = 1.0\n","    return x"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cz7L7PvkESFg","colab_type":"text"},"source":["# Step 0:  Prepare matrices\n","This includes:\n","* Load matrices \n","* Arrange matrices"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["data_dir = '../../data/sample_data/'\n","num_folds = 1\n"]},{"cell_type":"markdown","metadata":{},"source":["# Load data"]},{"cell_type":"code","execution_count":25,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"== Loading data from data_dir:  ../../data/sample_data/\n== Finish loading data from data_dir:  [0.83691185 0.82596964 0.77240981 0.80207477 0.76281822 0.77551997\n 0.80361883 0.79251464 0.78068612 0.76320014 0.79757753 0.79181566\n 0.81303564 0.8065129  0.83852059 0.79130437 0.82792796 0.80002413\n 0.85594075 0.78325622]\n"}],"source":["# load matrices\n","print(\"== Loading data from data_dir: \", data_dir)\n","U1 = pkl.load(open(data_dir+\"X_13.pkl\", 'rb'))\n","U2 = pkl.load(open(data_dir+\"X_14.pkl\", 'rb'))\n","V1 = pkl.load(open(data_dir+\"X_26.pkl\", 'rb'))\n","W1 = pkl.load(open(data_dir+\"X_53.pkl\", 'rb'))\n","r_temp_dict = {}\n","for fold_num in np.arange(1, num_folds+1):\n","    r_train = pkl.load(open(data_dir+'/X_12_train_fold_'+str(fold_num)+'.pkl', 'rb'))\n","    r_train_idx = pkl.load(open(data_dir+'/X_12_train_idx_'+str(fold_num)+'.pkl', 'rb'))\n","    r_test = pkl.load(open(data_dir+'/X_12_test_fold_'+str(fold_num)+'.pkl', 'rb'))\n","    r_test_idx = pkl.load(open(data_dir+'/X_12_test_idx_'+str(fold_num)+'.pkl', 'rb'))\n","    r_doublets = pkl.load(open(data_dir+'/R_doublets_'+str(fold_num)+'.pkl', 'rb'))\n","    r_temp_dict[fold_num] = {\"Rtrain\": r_train, \"Rtrain_idx\": r_train_idx, \"Rtest\": r_test, \"Rtest_idx\": r_test_idx, \"Rdoublets\": r_doublets}\n","\n","data_dict = {\"U1\": U1, \"U2\": U2, \"V1\": V1, \"W1\": W1, \"R\": r_temp_dict}\n","print(\"== Finish loading data from data_dir: \", U1[2])"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocess matrices\n","Load using a method from Monti et al."]},{"cell_type":"code","execution_count":32,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"torch: tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n        [0.8369, 0.8260, 0.7724,  ..., 0.8000, 0.8559, 0.7833],\n        ...,\n        [0.8135, 0.8352, 0.7965,  ..., 0.7297, 0.8365, 0.7799],\n        [0.8509, 0.8953, 0.7573,  ..., 0.8010, 0.8494, 0.7836],\n        [0.9231, 0.8716, 0.8780,  ..., 0.9730, 0.9534, 0.9023]],\n       dtype=torch.float64)\nnonzero: tensor([[  2,   0],\n        [  2,   1],\n        [  2,   2],\n        ...,\n        [999,  17],\n        [999,  18],\n        [999,  19]])\n"}],"source":["u1_trch = torch.from_numpy(U1)\n","a = torch.nonzero(u1_trch)\n","\n","print('torch:', u1_trch)\n","print('nonzero:', a)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from preprocessing import load_data_monti\n"]},{"cell_type":"code","execution_count":14,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"U1.shape:  (1000, 20)\nU2.shape:  (1000, 150)\nV1.shape:  (2000, 250)\nW1.shape:  (300, 20)\nR.shape:  (1000, 2000)\nU1 data: [[0.         0.         0.         ... 0.         0.         0.        ]\n [0.         0.         0.         ... 0.         0.         0.        ]\n [0.83691185 0.82596964 0.77240981 ... 0.80002413 0.85594075 0.78325622]\n ...\n [0.81349176 0.83518323 0.79653601 ... 0.72965597 0.83648859 0.77993258]\n [0.8508699  0.8952519  0.75729878 ... 0.80102254 0.84939108 0.78360706]\n [0.92305017 0.87163958 0.87802393 ... 0.97301008 0.95341843 0.90227069]]\n"}],"source":["print(\"U1.shape: \",U1.shape)\n","print(\"U2.shape: \",U2.shape)\n","print(\"V1.shape: \",V1.shape)\n","print(\"W1.shape: \",W1.shape)\n","print(\"R.shape: \",data_dict['R'][1]['Rtrain'].shape)\n","print(\"U1 data:\",U1)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["G = {\n","    \"e1\":[\"X1\",\"X2\",\"X3\"],\\\n","    \"e2\":[\"X1\",\"X4\"],\\\n","    \"e3\":[\"X2\",\"X5\"],\\\n","    \"e4\":[\"X3\"],\\\n","    \"e5\":[\"X5\"],\\\n","    \"e6\":[\"X4\"]}"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["X_data = {\n","    \"X1\":{\"1\":data_dict['R'][1][\"Rtrain\"]},\\\n","    \"X2\":{\"1\":U1},\\\n","    \"X3\":U2,\\\n","    \"X4\":V1,\\\n","    \"X5\":W1}"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["X_meta = {\n","    \"X1\":[\"e1\",\"e2\"],\\\n","    \"X2\":[\"e1\",\"e3\"],\\\n","    \"X3\":[\"e1\",\"e4\"],\\\n","    \"X4\":[\"e2\",\"e6\"],\\\n","    \"X5\":[\"e5\",\"e3\"]}"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["Rtest_triplets1 = [[1,1,1],[2,2,0]]\n","Rtest_triplets2 = [[1,1,1],[3,3,0],[1,2,0],[0,1,0],[0,2,0],[0,3,0]]"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["X_val = {\n","    \"X1\":{\"1\":Rtest_triplets1},\n","    \"X2\":{\"1\":Rtest_triplets2}\n","}"]},{"cell_type":"markdown","metadata":{"id":"fREOlaeVqp6C","colab_type":"text"},"source":["# Step 1: Select sub-matrix that shares common entities\n","\n","After arranging matrices, we will \n","* Select the size of sub-matrix *(m x n)* where 'm' is the size of common domain (i.e. user)"]},{"cell_type":"code","metadata":{"id":"J6ZFsjMsESFh","colab_type":"code","colab":{}},"source":["\n","\n","# Question: How to extract data from matrix and build it into subgraphs? Using torch_geometric! see documentation"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BpNRWf0Qhzwu","colab_type":"text"},"source":["# Step 2: Generate subgraphs for all matrix groups\n","\n","Do the following until cover all groups\n","* In one group, by using sub-matrix size from first step, loop connected matrices to generate multi-partite graphs.\n","* Please refer to step 3 for node-labelling process."]},{"cell_type":"markdown","metadata":{"id":"LgTrnc7zESFj","colab_type":"text"},"source":["# Step 3: Node labelling\n","\n","From arranged matrices, label them from 0 to N to build multipartite graph. For each entities, the label goes from N+1 to N+N, in the first hop. The following hops goes 2N+1 to 3N. So, the general formula for this node labelling is:\n","\n","> i x (N + k), \n","\n","where *i* is the number of hop, *N* is the number of involved matrices,*k* is the index of selected and arranged matrices\n","**bold text**\n"]},{"cell_type":"code","metadata":{"id":"tVrvfQnbESFk","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":306},"executionInfo":{"status":"ok","timestamp":1596160987311,"user_tz":-600,"elapsed":1038,"user":{"displayName":"Riordan Alfredo","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgLt9xRjtNZnB33NvOyHKPHq5AVG7hsg4zHVdcDCg=s64","userId":"12730100241040769811"}},"outputId":"687c24cf-46e2-43d7-a42d-469ce5a6a54d"},"source":["# below is just a sample model\n","# Prepare dummy variables \n","global_ids = np.array([0,3,3,3,3,3,1,4,4,4,4,4,2,5,5,5,5]) # assume 3 matrices: 0 = user; 1 = item; 2 = description\n","ids = torch.from_numpy(global_ids)\n","\n","# encode it\n","global_encoded = torch.from_numpy(one_hot(global_ids, max(global_ids)+1))\n","global_encoded"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0., 0.],\n","        [0., 0., 0., 1., 0., 0.],\n","        [0., 1., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1., 0.],\n","        [0., 0., 0., 0., 1., 0.],\n","        [0., 0., 1., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 0., 0., 1.],\n","        [0., 0., 0., 0., 0., 1.]], dtype=torch.float64)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"NcW8lOQXESFq","colab_type":"code","colab":{},"outputId":"7000f81a-77b4-485d-a4e8-0c3013b20831"},"source":["# parent = [target parent ids]\n","# children = [target child index, relationship weight]\n","\n","# user\n","user_parent = [[2,2],[2,2],[],[]]\n","user_children = [\\\n","                 [[0,4],[1,3]],\\\n","                 [[2,1],[3,4]],\\\n","                 [],\\\n","                 []\\\n","                ]\n","# item\n","item_parent = [[0,4],[0],[0,4],[0]]\n","item_children =[\\\n","                [[0,4],[0,1]],\\\n","                [[1,3]],\\\n","                [[2,1],[2,1]],\\\n","                [[3,4]]\\\n","               ]\n","\n","# feature\n","feature_parent = [[2],[2],[],[]]\n","feature_children = [[[0,1]],[[2,1]],[],[]]\n","\n","data = [user_parent, user_children, item_parent, item_children, feature_parent, feature_children]\n","data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[[2, 2], [2, 2], [], []],\n"," [[[0, 4], [1, 3]], [[2, 1], [3, 4]], [], []],\n"," [[0, 4], [0], [0, 4], [0]],\n"," [[[0, 4], [0, 1]], [[1, 3]], [[2, 1], [2, 1]], [[3, 4]]],\n"," [[2], [2], [], []],\n"," [[[0, 1]], [[2, 1]], [], []]]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"5ELyLedOESFt","colab_type":"code","colab":{}},"source":["# Question: How to merge similar relationship to make it undirected?"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RSyGaMqGESFw","colab_type":"text"},"source":["## Node labeling functions"]},{"cell_type":"code","metadata":{"tags":[],"id":"ZSavmK3sESFw","colab_type":"code","colab":{}},"source":["def get_parent_id(data, parent_id):\n","    all_parents_pos = [id for (id,item) in enumerate(data) if item % 2 == 0]    \n","    print('function', all_parents_pos)\n","    local_parent_id = int(parent_id/2) # give index 0,1,2 etc. from parent id 2,4,6 etc.\n","    parent_idx = all_parents_pos[local_parent_id]\n","    return parent_idx\n","\n","def get_relationships(idx):\n","    # variables\n","    # idx = index\n","    # pos = position\n","\n","    c_idx = idx\n","    target_parents = []\n","    target_children = []\n","\n","    all_parents_pos = [id for (id,item) in enumerate(global_ids) if item % 2 == 0]    \n","\n","    # calculate positions\n","    c_pos = global_ids[idx] # child position\n","    p_id = c_pos if(c_idx in all_parents_pos) else c_pos - 1\n","    local_parent_id = int(p_id/2) # give index 0,1,2 etc. from parent id 2,4,6 etc.\n","    p_idx = all_parents_pos[local_parent_id]\n","    cp_pos = c_idx - p_idx - 1\n","\n","    # return\n","    target_parents = data[p_idx][cp_pos] if(not p_idx == c_idx ) else data[p_id]\n","    target_children = data[c_pos][cp_pos] if(not p_idx == c_idx ) else data[p_id+1]\n","\n","    return [target_parents,target_children]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"id":"hAkwAwc-ESF1","colab_type":"code","colab":{},"outputId":"a9ce325b-8059-4ce4-8f9d-99c6ba5a45f1"},"source":["# Test\n","print('Node labels', global_ids)\n","\n","index = 7\n","relationships = get_relationships(index)\n","print('index:', index)\n","print('target parent:', relationships[0])\n","print('target weights:', relationships[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Node labels [0, 1, 1, 1, 1, 2, 3, 3, 3, 3, 4, 5, 5, 5, 5]\n","index: 7\n","target parent: [[2, 1]]\n","target weights: [[1, 3]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"unTH4Jmlp3F6","colab_type":"text"},"source":["# Step 4: Transform multipartite-graph into bipartite graphs"]},{"cell_type":"markdown","metadata":{"id":"4TvYCSJMESF3","colab_type":"text"},"source":["# Step 5: Group up similar bipartite-graphs for training"]},{"cell_type":"code","metadata":{"id":"H80YRxFjESF4","colab_type":"code","colab":{}},"source":["# Question: How to convert it to PyTorch, for training later?"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MtCPOOstESF6","colab_type":"text"},"source":["# Step 6: Train in GNN\n","\n","Use R-GCN with 'concat' + MLP\n","\n","Activation function: either Swish/ReLU by default\n","\n","Optimized using Adam optimizer (default)\n","\n","Reduce 'MSE' with customised loss function by considering layers (need a research paper about this)"]},{"cell_type":"code","metadata":{"id":"fIXZY0hWiYTK","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8l0eiUM5izSC","colab_type":"text"},"source":["# Questions/Problems\n","* How to deal the ranking problems? It happens in IGMC\n","* What will happen when we update a matrix?\n","* Can it be transferable for other dataset? It has to be inductive!"]},{"cell_type":"code","metadata":{"id":"JO1fDZvui2ag","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}